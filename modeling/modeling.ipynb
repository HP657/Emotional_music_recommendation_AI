{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"Training.xlsx\")\n",
    "df2 = pd.read_excel(\"Validation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop([\"연령\", \"성별\", \"신체질환\", \"상황키워드\", \"감정_소분류\",  \"시스템문장1\", \"시스템문장2\", \"시스템문장3\"], axis=1, inplace=True)\n",
    "df2.drop([\"연령\", \"성별\", \"신체질환\", \"상황키워드\", \"감정_소분류\",  \"시스템문장1\", \"시스템문장2\", \"시스템문장3\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={\"사람문장1\" : \"sentence\"}, inplace=True)\n",
    "df1.rename(columns={'감정_대분류': 'Emotion'}, inplace=True)\n",
    "\n",
    "df2.rename(columns={\"사람문장1\" : \"sentence\"}, inplace=True)\n",
    "df2.rename(columns={'감정_대분류': 'Emotion'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([\n",
    "    df1[['Emotion', 'sentence']],\n",
    "    df1[['Emotion', '사람문장2']].rename(columns={'사람문장2': 'sentence'}),\n",
    "    df1[['Emotion', '사람문장3']].rename(columns={'사람문장3': 'sentence'})\n",
    "], ignore_index=True)\n",
    "\n",
    "df_valid = pd.concat([\n",
    "    df2[['Emotion', 'sentence']],\n",
    "    df2[['Emotion', '사람문장2']].rename(columns={'사람문장2': 'sentence'}),\n",
    "    df2[['Emotion', '사람문장3']].rename(columns={'사람문장3': 'sentence'})\n",
    "], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_valid = df_valid.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"training_data.csv\", index=False)\n",
    "df_valid.to_csv(\"validation_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"training_data.csv\")\n",
    "df_valid = pd.read_csv(\"validation_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "temp = []\n",
    "for i in train['sentence']:\n",
    "    temp.append(okt.morphs(i))\n",
    "    \n",
    "temp = pd.Series(temp)\n",
    "train['token'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"training_data-token.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"training_data-token.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(df_train['token'], vector_size=1000, window=5, min_count=1, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'word_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Emotion                                     sentence  \\\n",
      "0          불안      사소한 것도 잊어버리는데 노후준비를 어디서부터 시작해야 할지 모르겠어.   \n",
      "1          불안                       부모님과의 진지한 대화시간을 가져야겠어.   \n",
      "2          불안         자식이라고 있으면 뭐해. 제 엄마가 어떻게 사는지 관심도 없는데.   \n",
      "3          불안                            책을 보거나 핸드폰을 해야겠지.   \n",
      "4          불안         평소 난폭한 아들이 병원비를 안 준다고 행패를 부릴까 봐 불안해.   \n",
      "...       ...                                          ...   \n",
      "11995      기쁨                       내가 평상시에 관심 있던 공부를 할거야.   \n",
      "11996      기쁨                            이제 내 건강에나 신경써야겠어.   \n",
      "11997      기쁨          언제 비가 올지 모르니까 우산 하나는 사물함에 놓고 다녀야겠어.   \n",
      "11998      기쁨     질병으로 죽을 때까지 고마운 마음으로 산다면 좋은 일이 생길지도 모른다.   \n",
      "11999      기쁨  응. 친구한테 고마워서 밥을 사긴 했는데 아직 상대를 완벽하게 꼬시지 못했어.   \n",
      "\n",
      "                                                   token  \n",
      "0      ['사소한', '것', '도', '잊어버리는데', '노후', '준비', '를', '...  \n",
      "1      ['부모님', '과의', '진지한', '대화', '시간', '을', '가져야겠어',...  \n",
      "2      ['자식', '이라고', '있으면', '뭐', '해', '.', '제', '엄마',...  \n",
      "3             ['책', '을', '보거나', '핸드폰', '을', '해야겠지', '.']  \n",
      "4      ['평소', '난폭한', '아들', '이', '병원', '비', '를', '안', ...  \n",
      "...                                                  ...  \n",
      "11995  ['내', '가', '평상시', '에', '관심', '있던', '공부', '를', ...  \n",
      "11996         ['이제', '내', '건강', '에나', '신경', '써야겠어', '.']  \n",
      "11997  ['언제', '비', '가', '올지', '모르니까', '우산', '하나', '는'...  \n",
      "11998  ['질병', '으로', '죽', '을', '때', '까지', '고마운', '마음',...  \n",
      "11999  ['응', '.', '친구', '한테', '고마워서', '밥', '을', '사긴',...  \n",
      "\n",
      "[12000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 불러옵니다.\n",
    "data = pd.read_csv('training_data-token.csv')  # 데이터 파일 경로에 맞게 수정하세요.\n",
    "\n",
    "# 각각의 감정에 대한 비율을 설정합니다.\n",
    "desired_ratio = {\n",
    "    '불안': 2000,\n",
    "    '분노': 2000,\n",
    "    '상처': 2000,\n",
    "    '슬픔': 2000,\n",
    "    '당황': 2000,\n",
    "    '기쁨': 2000\n",
    "}\n",
    "\n",
    "# 선택한 데이터를 저장할 빈 데이터프레임을 생성합니다.\n",
    "selected_data = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "# 각각의 감정에 대해 적절한 비율로 데이터를 선택합니다.\n",
    "for emotion, ratio in desired_ratio.items():\n",
    "    emotion_data = data[data['Emotion'] == emotion].sample(n=ratio, random_state=42)  # 적절한 비율로 샘플링\n",
    "    selected_data = pd.concat([selected_data, emotion_data], ignore_index=True)  # 데이터프레임을 합칩니다.\n",
    "\n",
    "# 선택된 데이터를 확인합니다.\n",
    "print(selected_data)\n",
    "\n",
    "# 선택된 데이터를 새로운 파일로 저장합니다.\n",
    "selected_data.to_csv('selected_data.csv', index=False)  # 저장할 파일명에 맞게 수정하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n",
      "불안    2000\n",
      "분노    2000\n",
      "상처    2000\n",
      "슬픔    2000\n",
      "당황    2000\n",
      "기쁨    2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 불러옵니다.\n",
    "data = pd.read_csv('selected_data.csv')\n",
    "emotion_counts = data['Emotion'].value_counts()\n",
    "print(emotion_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_embedding(model, embedding_size, tokenized_words):\n",
    "    feature_vec = np.zeros((embedding_size,), dtype=\"float32\")\n",
    "    n_words = 0\n",
    "    for word in tokenized_words:\n",
    "        if word in model.wv.key_to_index:\n",
    "            n_words += 1\n",
    "            feature_vec = np.add(feature_vec, model.wv[word])\n",
    "    if (n_words > 0):\n",
    "        feature_vec = np.divide(feature_vec, n_words)\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('selected_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from joblib import load, dump\n",
    "\n",
    "model = load(\"word_model.joblib\")\n",
    "\n",
    "X = [get_sent_embedding(model, 1000, tokens) for tokens in df_train['token']]\n",
    "y = df_train['Emotion']\n",
    "\n",
    "# SVM 분류 모델 학습\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X, y)\n",
    "\n",
    "# 모델 저장\n",
    "dump(svm_model, 'svm_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = 1\n",
    "joblib.dump(svm_model, 'svm_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
